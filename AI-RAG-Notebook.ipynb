{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1929e1-3fac-4f5b-b397-182fd0cc728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Using cached kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: bleach in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in /Users/yusra/rag_env/lib/python3.12/site-packages (from kaggle) (0.5.1)\n",
      "Using cached kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.7.4.5 python-slugify-8.0.4 text-unidecode-1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a55b1-1113-4d69-9a14-c59cc5a0bcef",
   "metadata": {},
   "source": [
    "Kaggle k√ºt√ºphanesini y√ºkleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "436c992e-9cbb-4006-bffe-c181be109281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d62007-cf38-4fc5-bd79-fa244d1dfcf7",
   "metadata": {},
   "source": [
    "Kaggle API i√ßin konfig√ºrasyon dizinini ayarlama. Kaggle API anahtarƒ±nƒ±n bulunduƒüu dizini belirler (~/.kaggle dizini)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b376e9-1c38-4d29-b802-92efa8877a16",
=======
   "id": "1c01ecee-7fd0-4579-9a41-86c4f98647b0",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/yusra/Desktop/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/antoinebourgois2/wikipedia-ai-glossary\n",
      "License(s): CC0-1.0\n",
      "wikipedia-ai-glossary.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
=======
      "‚úÖ Local dataset found. Skipping Kaggle download.\n",
      "Loaded dataset with 343 rows.\n"
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "!kaggle datasets download -d antoinebourgois2/wikipedia-ai-glossary -p ./data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b1016-2acc-42f0-b5b6-be4580319d90",
   "metadata": {},
   "source": [
    "Kaggle veri setini indirme. Belirtilen Kaggle veri setini 'data' klas√∂r√ºne indirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d40afd8-1889-4f9d-8a3e-e5621cbcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('./data/wikipedia-ai-glossary.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af8afc-d274-470a-b1d0-d8fe90262e19",
   "metadata": {},
   "source": [
    "ƒ∞ndirilen zip dosyasƒ±nƒ± 'data' klas√∂r√ºne √ßƒ±karƒ±r."
=======
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# Veri dosyasƒ± kontrol√º\n",
    "# -------------------------------\n",
    "data_path = './data/Wikipedia_AI_Glossary.csv'\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"üì¶ Dataset not found locally. Downloading from Kaggle...\")\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = os.path.expanduser('~/.kaggle')\n",
    "    !kaggle datasets download -d antoinebourgois2/wikipedia-ai-glossary -p ./data\n",
    "    with zipfile.ZipFile('./data/wikipedia-ai-glossary.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data/')\n",
    "    print(\"‚úÖ Dataset downloaded and extracted.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚úÖ Local dataset found. Skipping Kaggle download.\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Loaded dataset with {len(df)} rows.\")\n"
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "id": "89ba8184-3f95-4842-9ad5-5def8227d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wikipedia_AI_Glossary.csv', 'wikipedia-ai-glossary.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('./data'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578d1a2-454c-4e7a-9ece-b26500ba74e3",
   "metadata": {},
   "source": [
    "data' klas√∂r√ºndeki dosyalarƒ± listeler, CSV dosyasƒ±nƒ±n orada olduƒüunu doƒürular."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "id": "52da9caa-5fc3-4294-98fd-b7700d2d7441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Link', 'Title', 'Wikipedia_page_description',\n",
      "       'High_dimensional_embeddings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/Wikipedia_AI_Glossary.csv')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7fec1-5859-4296-9924-4e9e6f6056a8",
   "metadata": {},
   "source": [
    "CSV dosyasƒ±nƒ± bir DataFrame olarak okur ve kolon isimlerini g√∂sterir."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "id": "b7ce2cbd-5319-472a-9656-5455b64875e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a196f-7a04-4eb7-bc2f-5bb73044e924",
   "metadata": {},
   "source": [
    "Gerekli k√ºt√ºphaneleri y√ºkleme.\n",
    "\n",
    "SentenceTransformers: metinleri vekt√∂rlere d√∂n√º≈üt√ºrmek i√ßin\n",
    "\n",
    "ChromaDB: vekt√∂r tabanlƒ± veri deposu i√ßin\n",
    "\n",
    "Transformers: QA modeli i√ßin\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 5,
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "id": "4b3341fb-2686-4c73-8f9f-6731107a2438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset boyutu: 343\n",
      "√ñrnek terim: abductive logic programming\n",
      "√ñrnek a√ßƒ±klama: Logic programming using abductive reasoningAbductive logic programming ALP is a high-level knowledge-representation framework that can be used to solve problems declaratively, based on abductive reasoning. It extends normal logic programming by allowing some predicates to be incompletely defined, declared as abducible predicates. Problem solving is effected by deriving hypotheses on these abducible predicates abductive hypotheses as solutions of problems to be solved. These problems can be either observations that need to be explained as in classical abduction or goals to be achieved as in normal logic programming. It can be used to solve problems in diagnosis, planning, natural language and machine learning. It has also been used to interpret negation as failure as a form of abductive reasoning.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv('./data/Wikipedia_AI_Glossary.csv')\n",
    "df = df.dropna(subset=[\"Title\", \"Wikipedia_page_description\"])\n",
    "df[\"Wikipedia_page_description\"] = df[\"Wikipedia_page_description\"].apply(lambda x: x.replace(\"\\n\", \" \").strip())\n",
    "texts = df[\"Wikipedia_page_description\"].tolist()\n",
    "\n",
    "print(f\"Dataset boyutu: {len(df)}\")\n",
    "print(f\"√ñrnek terim: {df['Title'].iloc[0]}\")\n",
    "print(f\"√ñrnek a√ßƒ±klama: {texts[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb63967-7118-4001-8f9f-1a58c0319353",
   "metadata": {},
   "source": [
    "Title veya Wikipedia_page_description bo≈ü olan satƒ±rlarƒ± siler. Dataset boyutu 343't√ºr.\n",
    "\n",
    "Satƒ±r sonu karakterlerini kaldƒ±rƒ±r ve metni temizler ve a√ßƒ±klamalarƒ± bir listeye d√∂n√º≈üt√ºr√ºr.\n",
    "\n",
    "printf ile dataset boyutu ve √∂rnek veriyi g√∂sterir."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 7,
   "id": "5570c6ad-4a95-4040-978d-f2afc214a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Orijinal metin sayƒ±sƒ±: 343\n",
      "üîπ Chunk (par√ßa) sayƒ±sƒ±: 2241\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Metinleri k√º√ß√ºk par√ßalara (chunks) ayƒ±rma\n",
    "# -------------------------------\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Chunk parametreleri: her par√ßa 300 karakter, 50 karakter √∂rt√º≈üme\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\". \", \", \", \"\\n\", \" \"]\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for i, text in enumerate(texts):\n",
    "    # Her a√ßƒ±klamayƒ± k√º√ß√ºk par√ßalara b√∂l\n",
    "    sub_texts = splitter.split_text(text)\n",
    "    for j, chunk in enumerate(sub_texts):\n",
    "        chunks.append({\n",
    "            \"id\": f\"{i}_{j}\",\n",
    "            \"text\": chunk\n",
    "        })\n",
    "\n",
    "print(f\"üîπ Orijinal metin sayƒ±sƒ±: {len(texts)}\")\n",
    "print(f\"üîπ Chunk (par√ßa) sayƒ±sƒ±: {len(chunks)}\")\n",
    "\n",
    "# Embedding i√ßin yeni metin listesi\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "ids = [c[\"id\"] for c in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "execution_count": 8,
   "id": "ec7176d9-7df9-4277-a3c5-0088508862f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "d777146bc1254b4e96b6cbfadd6539fe",
=======
       "model_id": "315dec3b136f49268998d4d67d5d007f",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "357bfb492f914a5e98723f8bb3652a4d",
=======
       "model_id": "d5e2120cd3aa4d8ea7d6f868c8d53845",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "c02221bd93f04fdfa35b5ed5ee534720",
=======
       "model_id": "a77c9fe4466d49dd9da98d5c01b226b9",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "07c48801a7f9474fa9042f92fbe404fa",
=======
       "model_id": "63cc36c9c56642f0b66dd52150b643fd",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "32d2938f52ff46ecb3c5beef92259290",
=======
       "model_id": "d2b263a4a6c54defb52fa3cb8c485bbf",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "9cc5bf13737146f997b0a76483195337",
=======
       "model_id": "bb98ddcd537c4304991557752091e446",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "c6f78a989c7540fb9b01acbf3d8f1cb4",
=======
       "model_id": "bba951117073426b9cceed94420cf573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637dc36c0ff847cf88049071fd77385e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d01e8358e7464bacfe8b870e04d265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac90006e99d14d1b9062ae851d88f352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476122c6a59247d998e772b35b33beb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd010e9cb814cbea88d74e187a20344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cbc943ad1d4872be3485904076efe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a945ac6fe451478dba0675b067f6f36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b8f645a84f4c2aab56f1aa38f4a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd227bf196574b57a09eb30444b122d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dc77d901fd4549a10f46f28fcd0f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd63a08024d54906bf55a12ac1bcd553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8553a0e4e74ed79e7e7f66082b1303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cbf5df39434c45b52725205dc8b8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afed27ae34a6417993a550ca1508a33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464f9e8d95684151887aa7d8e178101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a1695f59ab40e5a3df77be86b62ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69ea03ce08f46c599f72505c919ca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b1882a69964605a8b983c2ea6e6c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25f0c10fd1d4d8d9374fbdeda5e94e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56500a8f25d142578efc51156a134fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee622776977416095cb33edf4e851ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbcfc920f344df2b3b56b37f9229de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0606b2e179ac4f66b2742dc1402bc31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b19e758940447a4b33a58e1ed257161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04688f9b88f9459ead8538d732b657c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81879064581e4cc1bef1b3e2f7bd840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faa0c5cde474506b159d466ea809431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbe7f35dbc64d5d8777e92a85351ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420c988d58ea44b2aa1a574d8c8e403b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2c967a9a394d34ba316d50ce6f114b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba2192f74884ba9b96a6652cf684993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34edd64e35f4468ba3e102dd5dc924c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f36102bd924aa29bc2918c2dbf7612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829fe974617642b5831f3027d946a91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec38265bd8fb4fe1862b013a95da33e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d42b49b8aa4513a7465add78929b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e884d32882934ceab8dd64e00a144335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135f4be4fcb5492d81a8932bdbb842b6",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Embeddings (batch ile)\n",
    "# -------------------------------\n",
=======
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = []\n",
    "batch_size = 50\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    batch_embeddings = embedder.encode(batch, show_progress_bar=True)\n",
<<<<<<< HEAD
    "    embeddings.extend(batch_embeddings)\n",
    "\n"
=======
    "    embeddings.extend(batch_embeddings)\n"
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ed705-5277-4b57-97d9-0cd356a99799",
   "metadata": {},
   "source": [
    "Metinleri vekt√∂rlere d√∂n√º≈üt√ºrmek i√ßin √∂nceden eƒüitilmi≈ü modeli y√ºkler.\n",
    "\n",
    "Metinleri 50'lik batchler halinde vekt√∂rle≈ütirir ve embeddings listesine ekler."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "id": "096eb5ef-9c42-46c5-9de1-c201e0ca62f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Chroma Vector Store\n",
    "# -------------------------------\n",
    "client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "\n",
    "if \"ai_glossary\" in [c.name for c in client.list_collections()]:\n",
    "    client.delete_collection(\"ai_glossary\")\n",
    "\n",
    "collection = client.create_collection(\"ai_glossary\")\n",
    "for i, (text, emb) in enumerate(zip(texts, embeddings)):\n",
    "    collection.add(documents=[text], embeddings=[emb.tolist()], ids=[str(i)])\n"
=======
   "execution_count": 10,
   "id": "096eb5ef-9c42-46c5-9de1-c201e0ca62f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunk'lƒ± veriler ba≈üarƒ±yla Chroma'ya eklendi!\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Chroma Vector Store (Chunk verisiyle)\n",
    "# -------------------------------\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "\n",
    "# Eski koleksiyon varsa sil\n",
    "if \"ai_glossary\" in [c.name for c in client.list_collections()]:\n",
    "    client.delete_collection(\"ai_glossary\")\n",
    "\n",
    "# Yeni koleksiyon olu≈ütur\n",
    "collection = client.create_collection(\"ai_glossary\")\n",
    "\n",
    "# Chunk'larƒ± ekle\n",
    "for i, (text, emb) in enumerate(zip(texts, embeddings)):\n",
    "    collection.add(\n",
    "        documents=[text],\n",
    "        embeddings=[emb.tolist()],\n",
    "        ids=[str(i)]\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Chunk'lƒ± veriler ba≈üarƒ±yla Chroma'ya eklendi!\")\n"
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c2735-88d8-4d0f-b076-9311480ccb25",
   "metadata": {},
   "source": [
    "ChromaDB istemcisi olu≈üturur (telemetri kapalƒ±).\n",
    "\n",
    "Eƒüer collection zaten varsa, √∂nce siler.\n",
    "\n",
    "Her metni ve embedding'i ChromaDB collection'ƒ±na ekler."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 11,
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "id": "fb35986b-2b1b-4073-8d6a-15e075ca9667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ QA Model (Tiny Flan-T5)\n",
    "# -------------------------------\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", tokenizer=\"google/flan-t5-small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d44e921-bd67-4973-97f9-9813b0be6284",
   "metadata": {},
   "source": [
    "Flan-T5 k√º√ß√ºk modeli ile text2text QA pipeline olu≈üturur."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "id": "8de129ff-928d-42fd-8bfc-a9be001534e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ RAG Query Fonksiyonu\n",
    "# -------------------------------\n",
    "def rag_query(question, top_k=3):\n",
=======
   "execution_count": 12,
   "id": "8de129ff-928d-42fd-8bfc-a9be001534e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ RAG Query Fonksiyonu (Chunk destekli)\n",
    "# -------------------------------\n",
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", tokenizer=\"google/flan-t5-base\")\n",
    "\n",
    "def rag_query(question, top_k=5):\n",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
    "    query_vec = embedder.encode([question])\n",
    "    results = collection.query(query_embeddings=query_vec.tolist(), n_results=top_k)\n",
    "    top_docs = results[\"documents\"][0]\n",
    "\n",
<<<<<<< HEAD
    "    context = \" \".join(top_docs)\n",
    "    context = context[:3000]  # Uzun context i√ßin limit\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI expert. Answer the question using the following context.\n",
    "Provide a detailed explanation in 3-5 sentences.\n",
=======
    "    # En alakalƒ± chunk'larƒ± birle≈ütir\n",
    "    context = \" \".join(top_docs)\n",
    "    context = context[:1500]  # g√ºvenli context limiti\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI expert. Provide a clear and concise answer (3‚Äì5 sentences).\n",
    "Use the provided context if needed, but avoid repeating it directly.\n",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
<<<<<<< HEAD
    "    answer = qa_model(prompt, max_new_tokens=600, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
=======
    "\n",
    "    answer = qa_model(prompt, max_new_tokens=250, do_sample=False)[0][\"generated_text\"]\n",
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
    "    return answer.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c55de-1e99-4436-9154-1b8d54bcf49f",
   "metadata": {},
   "source": [
    "Soruyu embedding'e d√∂n√º≈üt√ºr√ºr, ChromaDB'den en benzer top_k dok√ºmanƒ± alƒ±r.\n",
    "\n",
    "Dok√ºmanlarƒ± birle≈ütirip uzunluƒüu 3000 token ile sƒ±nƒ±rlar.\n",
    "\n",
    "QA modeline promptu verir ve yanƒ±t √ºretir.\n",
    "\n",
    "Fonksiyon, soruya RAG mantƒ±ƒüƒ±yla yanƒ±t d√∂ner."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 13,
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   "id": "e1d04c8d-0f64-457a-a5fb-0bd912c13b48",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is NLP?\n",
      "Answer: An interdisciplinary subfield of computer science and linguistics.\n"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is a Transformer in AI?\n",
      "A: deep neural networks\n"
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 7Ô∏è‚É£ Test Soru\n",
    "# -------------------------------\n",
<<<<<<< HEAD
    "question = \"What is NLP?\"\n",
    "answer = rag_query(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
=======
    "question = \"What is a Transformer in AI?\"\n",
    "answer = rag_query(question)\n",
    "print(f\"Q: {question}\\nA: {answer}\")\n"
>>>>>>> c60be98 (Update app.py, notebook, and requirements with latest changes)
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4757f4-0ffb-4f36-b443-094526caf784",
   "metadata": {},
   "source": [
    "√ñrnek bir soruyu RAG fonksiyonuna sorar ve yanƒ±tƒ± yazdƒ±rƒ±r."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
